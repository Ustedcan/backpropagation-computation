# backpropagation-computation

__TÃ­tulo: ImplementaciÃ³n de una ComputaciÃ³n con Backpropagation usando Micrograd__
Indicaciones: Resuelva el ejercicio propuesto segÃºn las indicaciones dadas. Posteriormente, 
subir su resultado al aula virtual hasta la fecha de finalizaciÃ³n asignada.  
Indicaciones: 
Implementar la expresiÃ³n matemÃ¡tica dada en Python utilizando la biblioteca micrograd, 
asegurando que los valores sean correctamente almacenados como nodos computacionales y que 
el cÃ¡lculo de gradientes se realice de manera automÃ¡tica mediante backpropagation. 
ExpresiÃ³n MatemÃ¡tica a Implementar: 
ï¿½
ï¿½
 ğ¿ =((ğ‘ğ‘Ã—ğ‘ğ‘+ğ‘ğ‘)2+ğ‘‘ğ‘‘+ğ‘’ğ‘’Ã—ğ‘“ğ‘“)Ã—ğ‘”ğ‘” 
Donde: 
â€¢ a, b, c, d, e, f, g son valores de entrada 
â€¢ Se debe realizar el cÃ¡lculo del gradiente de L con respecto a todas las variables mediante 
backpropagation. 
Requerimientos: 
1. Definir las variables como instancias de Value de micrograd, asegurando que cada 
variable tenga una etiqueta representativa. 
2. Construir la expresiÃ³n matemÃ¡tica paso a paso en cÃ³digo, asegurando que cada 
operaciÃ³n intermedia tenga una etiqueta clara. 
3. Realizar la backpropagation para obtener los gradientes de todas las variables 
involucradas en la ecuaciÃ³n.
